import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE


df = pd.read_csv("../data/train_transaction.csv")

# Drop columns with more than 50% missing values
df = df.dropna(thresh=len(df) * 0.5, axis=1)

# Encode categorical variables
df = pd.get_dummies(df, drop_first=True)

# Fill remaining NaNs with mean
df.fillna(df.mean(), inplace=True)

# Separate features and target
X = df.drop(columns=["isFraud"])  # Features
y = df["isFraud"]  # Target

# Normalize numerical data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print(f"Resampled Training Data: {X_train_resampled.shape}, {y_train_resampled.shape}")

# Save processed data
processed_data = pd.DataFrame(X_scaled, columns=X.columns)
processed_data["isFraud"] = y
processed_data.to_csv("../data/processed_data.csv", index=False)

print("âœ… Data Preprocessing Complete. File saved at '../data/processed_data.csv'")
